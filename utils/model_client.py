import os
import json
import time
import base64
from typing import Dict, Any, Optional, List, Callable
from openai import OpenAI, AzureOpenAI
from .providers.azure_openai import chat_completion as azure_chat
from .providers.azure_openai import chat_stream_completion as azure_chat_stream
from .providers.openai_generic import chat_completion as openai_chat
from .logging_utils import ts_print

class ModelClient:
    """ç»Ÿä¸€æ¨¡å‹å®¢æˆ·ç«¯ï¼Œæ”¯æŒå¤šç§æ¨¡å‹ï¼ˆæ— é¢å¤–é…é¢/é™æµæ§åˆ¶ï¼‰"""
    
    def __init__(self):
        self.config = self._load_config()
        self._check_environment_variables()

    # ç§»é™¤Azureé™æµä¸é…é¢é€»è¾‘ï¼›ç›´æ¥è°ƒç”¨
        
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½å¹¶å¤„ç†æ¨¡å‹é…ç½®ï¼ˆä¸¥æ ¼è¦æ±‚é…ç½®æ–‡ä»¶å­˜åœ¨ä¸”å¯è§£æï¼‰"""
        import yaml
        config_path = 'configs/models.yaml'
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Missing model config: {config_path}")
        with open(config_path, 'r') as f:
            file_config = yaml.safe_load(f)
        if not isinstance(file_config, dict) or 'models' not in file_config:
            raise ValueError("Invalid models.yaml: missing 'models' key")
        # ç¯å¢ƒå˜é‡æ›¿æ¢ï¼ˆprovider ç”±é…ç½®æ˜¾å¼æä¾›ï¼‰
        models = {}
        for model_name, model_config in file_config.get('models', {}).items():
            api_key = model_config.get('api_key', '')
            if isinstance(api_key, str) and api_key.startswith('${') and api_key.endswith('}'):
                env_var = api_key[2:-1]
                model_config['api_key'] = os.getenv(env_var)
            models[model_name] = model_config
        return {'models': models}
    
    def _check_environment_variables(self):
        """æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡"""
        missing_vars = []
        
        for model_name, model_config in self.config['models'].items():
            api_key = model_config.get('api_key')
            if not api_key:
                if model_config['provider'] == 'openai':
                    missing_vars.append(f"OPENAI_API_KEY (for {model_name})")
                elif model_config['provider'] == 'azure_openai':
                    missing_vars.append(f"AZURE_OPENAI_API_KEY (for {model_name})")
        
        if missing_vars:
            raise ValueError(f"Missing environment variables: {', '.join(missing_vars)}")
    
    def _get_client(self, model_name: str):
        """è·å–æ¨¡å‹å®¢æˆ·ç«¯"""
        model_config = self.config['models'][model_name]
        api_key = model_config['api_key']
        
        if model_config['provider'] == 'azure_openai':
            return AzureOpenAI(
                api_version=model_config.get('api_version', '2024-12-01-preview'),
                azure_endpoint=model_config['azure_endpoint'],
                api_key=api_key
            )
        elif model_config['provider'] == 'local':
            return OpenAI(
                base_url=model_config['base_url'],
                api_key=api_key
            )
        else:  # openai
            return OpenAI(api_key=api_key)
    
    def _is_rate_limit_error(self, error: Exception) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º429é”™è¯¯"""
        error_str = str(error)
        return '429' in error_str
    
    async def call_model_with_gpt5_params(self, model_name: str, prompt: str, 
                                         images: Optional[List[str]] = None,
                                         temperature: float = 0.3,
                                         verbosity: str = "medium", 
                                         reasoning_effort: str = "medium",
                                         stream_callback: Optional[Callable[[str], None]] = None) -> str:
        """è°ƒç”¨æ¨¡å‹API - GPT-5ä¸“ç”¨ç‰ˆæœ¬ï¼Œæ”¯æŒverbosityå’Œreasoning_effortå‚æ•°"""
        import asyncio

        client = self._get_client(model_name)
        model_config = self.config['models'][model_name]
        is_local = model_config['provider'] == 'local'
        
        # æ„å»ºæ¶ˆæ¯
        messages = []
        if images:
            content = [{"type": "text", "text": prompt}]
            for image_base64 in images:
                content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/png;base64,{image_base64}"}
                })
            messages.append({"role": "user", "content": content})
        else:
            messages.append({"role": "user", "content": prompt})

        for attempt in range(5):
            try:
                if model_config['provider'] == 'azure_openai':
                    # Offload synchronous SDK call to a thread to avoid blocking the event loop
                    model_type = model_config.get('type', '').lower()

                    # Streaming path (if callback provided)
                    if stream_callback is not None:
                        max_tokens = model_config.get('max_tokens', 16384)
                        loop = asyncio.get_event_loop()
                        return await loop.run_in_executor(
                            None,
                            lambda: azure_chat_stream(
                                client,
                                model_config['deployment'],
                                messages,
                                max_completion_tokens=max_tokens,
                                stream_callback=stream_callback,
                            ),
                        )

                    # Non-streaming path
                    def _do_call():
                        max_tokens = model_config.get('max_tokens', 16384)
                        if 'o1' in model_type or 'gpt-5' in model_type:
                            return azure_chat(
                                client,
                                model_config['deployment'],
                                messages,
                                max_completion_tokens=max_tokens,
                                temperature=None,
                            )
                        else:
                            return azure_chat(
                                client,
                                model_config['deployment'],
                                messages,
                                max_completion_tokens=max_tokens,
                                temperature=temperature,
                            )

                    loop = asyncio.get_event_loop()
                    return await loop.run_in_executor(None, _do_call)
                else:
                    # å…¶ä»–æä¾›å•†ä½¿ç”¨å¸¸è§„è°ƒç”¨
                    return await self.call_model(model_name, prompt, images, temperature)
                
            except Exception as e:
                import sys
                ts_print(f"GPT-5 API call error (attempt {attempt + 1}/5): {type(e).__name__}: {str(e)}", file=sys.stderr)
                if self._is_rate_limit_error(e):
                    await asyncio.sleep(2 ** attempt)
                    continue
                if attempt == 4:
                    raise e
                # å¯¹äºé429é”™è¯¯ï¼Œä¹Ÿè¦ç»§ç»­é‡è¯•
                await asyncio.sleep(1)
                continue
        
        raise Exception("Max retries exceeded")

    async def call_model(self, model_name: str, prompt: str, 
                   images: Optional[List[str]] = None,
                   temperature: float = 0.3) -> str:
        """å¼‚æ­¥è°ƒç”¨æ¨¡å‹API"""
        import asyncio
        
        client = self._get_client(model_name)
        model_config = self.config['models'][model_name]
        
        # æœ¬åœ°æ¨¡å‹ä½¿ç”¨æ— é™é‡è¯•ï¼Œäº‘ç«¯æ¨¡å‹ä½¿ç”¨æœ‰é™é‡è¯•
        is_local = model_config.get('provider') == 'local'
        max_retries = float('inf') if is_local else 5
        
        # æ„å»ºæ¶ˆæ¯
        if images:
            content = [{"type": "text", "text": prompt}]
            for img_path in images:
                if img_path.startswith("data:image"):
                    # å·²ç»æ˜¯å®Œæ•´çš„data URLæ ¼å¼
                    base64_image = img_path
                elif (("/" in img_path or "\\" in img_path) and 
                      not img_path.startswith(("iVBOR", "/9j", "UklG")) and
                      len(img_path) < 1000):
                    # æ–‡ä»¶è·¯å¾„æ ¼å¼ - éœ€è¦åŒæ—¶æ»¡è¶³ï¼š
                    # 1. åŒ…å«è·¯å¾„åˆ†éš”ç¬¦
                    # 2. ä¸ä»¥å¸¸è§å›¾ç‰‡æ ¼å¼çš„base64å¼€å¤´ (PNG: iVBOR, JPEG: /9j, WEBP: UklG)
                    # 3. é•¿åº¦åˆç†(æ–‡ä»¶è·¯å¾„é€šå¸¸ä¸ä¼šè¶…è¿‡1000å­—ç¬¦)
                    with open(img_path, "rb") as f:
                        base64_data = base64.b64encode(f.read()).decode()
                    base64_image = f"data:image/png;base64,{base64_data}"
                else:
                    # çº¯base64å­—ç¬¦ä¸²ï¼ˆæ¥è‡ªbrowser.screenshot()ï¼‰
                    base64_image = f"data:image/png;base64,{img_path}"
                content.append({
                    "type": "image_url",
                    "image_url": {"url": base64_image}
                })
            messages = [{"role": "user", "content": content}]
        else:
            messages = [{"role": "user", "content": prompt}]
        
        # é‡è¯•æœºåˆ¶
        attempt = 0
        while True:
            try:
                # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡ŒåŒæ­¥çš„APIè°ƒç”¨
                def _make_request():
                    # Azure OpenAI vs generic OpenAI-compatible providers
                    if model_config['provider'] == 'azure_openai':
                        model_type = model_config.get('type', '').lower()
                        max_tokens = model_config.get('max_tokens', 16384)
                        if 'o1' in model_type or 'gpt-5' in model_type:
                            return azure_chat(
                                client,
                                model_config['deployment'],
                                messages,
                                max_completion_tokens=max_tokens,
                                temperature=None,
                            )
                        else:
                            return azure_chat(
                                client,
                                model_config['deployment'],
                                messages,
                                max_completion_tokens=max_tokens,
                                temperature=temperature,
                            )
                    else:
                        model_identifier = model_config.get('model', model_config.get('deployment'))
                        max_tokens = model_config.get('max_tokens', 16384)
                        return openai_chat(
                            client,
                            model_identifier,
                            messages,
                            temperature=temperature,
                            max_tokens=max_tokens,
                        )
                
                # å¼‚æ­¥æ‰§è¡Œç½‘ç»œè¯·æ±‚ï¼ˆæ— é¢å¤–é™æµï¼‰
                import asyncio
                loop = asyncio.get_event_loop()
                response_content = await loop.run_in_executor(None, _make_request)
                
                # è°ƒè¯•ï¼šå¯¹äºæœ¬åœ°æ¨¡å‹ï¼Œå¦‚æœè¿”å›å†…å®¹å¾ˆçŸ­ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
                if is_local and response_content and len(response_content) < 10:
                    ts_print(f"ğŸ” {model_name} returned short response ({len(response_content)} chars): {repr(response_content)}")
                
                return response_content
                
            except Exception as e:
                attempt += 1
                
                # æœ¬åœ°æ¨¡å‹ï¼šæ‰€æœ‰é”™è¯¯éƒ½é‡è¯•ï¼ˆæ— é™é‡è¯•ï¼‰
                if is_local:
                    error_msg = str(e)[:100]
                    retry_delay = min(2 + attempt * 0.5, 10)
                    import sys
                    ts_print(f"ğŸ”„ Local model {model_name} error (attempt {attempt}): {error_msg}... retrying in {retry_delay:.1f}s", file=sys.stderr)
                    sys.stderr.flush()
                    await asyncio.sleep(retry_delay)
                    continue
                
                # äº‘ç«¯æ¨¡å‹ï¼šåªåœ¨429é”™è¯¯æ—¶é‡è¯•ï¼Œæœ‰é™æ¬¡æ•°
                if self._is_rate_limit_error(e) and attempt <= max_retries:
                    ts_print(f"â¸ï¸ Rate limit (429), retrying in 2s (attempt {attempt}/{max_retries + 1})")
                    await asyncio.sleep(2)
                    continue
                
                # å…¶ä»–é”™è¯¯æˆ–é‡è¯•è€—å°½ï¼Œç›´æ¥æŠ›å‡º
                raise e
    
    async def call_operator_model(self, prompt: str, screenshot: Optional[str] = None) -> str:
        """è°ƒç”¨operatoræ¨¡å‹ä½¿ç”¨computer-use-preview API"""
        import asyncio
        
        client = self._get_client('operator')
        model_config = self.config['models']['operator']
        
        # æ„å»ºinputæŒ‰ç…§OpenAI computer-useæ ¼å¼
        content = [{"type": "input_text", "text": prompt}]
        
        if screenshot:
            if screenshot.startswith("data:image"):
                base64_image = screenshot
            elif (("/" in screenshot or "\\" in screenshot) and 
                  not screenshot.startswith(("iVBOR", "/9j", "UklG")) and
                  len(screenshot) < 1000):
                # æ–‡ä»¶è·¯å¾„æ ¼å¼
                with open(screenshot, "rb") as f:
                    base64_data = base64.b64encode(f.read()).decode()
                base64_image = f"data:image/png;base64,{base64_data}"
            else:
                # çº¯base64å­—ç¬¦ä¸²
                base64_image = f"data:image/png;base64,{screenshot}"
            
            content.append({
                "type": "input_image",
                "image_url": base64_image
            })
        
        input_data = [{"role": "user", "content": content}]
        
        # é‡è¯•æœºåˆ¶ - OpenAIæœ‰é™é‡è¯•
        max_retries = 5
        attempt = 0
        
        while True:
            try:
                def _make_request():
                    # Use deployment for Azure OpenAI, model for regular OpenAI
                    model_param = model_config.get('deployment', model_config.get('type', model_config.get('model')))
                    
                    response = client.responses.create(
                        model=model_param,
                        tools=[{
                            "type": "computer_use_preview",
                            "display_width": model_config.get('display_width', 1920),
                            "display_height": model_config.get('display_height', 1080),
                            "environment": model_config.get('environment', 'browser')
                        }],
                        input=input_data,
                        truncation="auto"
                    )
                    return response
                
                import asyncio
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(None, _make_request)
                
                # è¿”å›åŸå§‹OpenAIå“åº”å¯¹è±¡ï¼Œè®©OperatorCUAPolicyå¤„ç†
                return response
                
            except Exception as e:
                attempt += 1
                error_msg = str(e)[:100]
                
                # æœ‰é™é‡è¯•
                if attempt > max_retries:
                    ts_print(f"âŒ {model_config.get('deployment', 'operator')} model failed after {max_retries} attempts: {error_msg}")
                    raise e
                
                # é‡è¯•é€»è¾‘
                retry_delay = 2
                ts_print(f"ğŸ”„ {model_config.get('deployment', 'operator')} model error (attempt {attempt}/{max_retries}): {error_msg}... retrying in {retry_delay}s")
                await asyncio.sleep(retry_delay)
                continue

    async def call_operator_initial(self, prompt: str, screenshot: Optional[str] = None,
                                    *, display_width: int = 1280, display_height: int = 720,
                                    environment: str = 'browser'):
        """Operator initial call using Responses API with computer_use_preview tool (truncation=auto)"""
        import asyncio

        client = self._get_client('operator')
        model_config = self.config['models']['operator']

        # Build input content
        content = [{"type": "input_text", "text": prompt}]
        if screenshot:
            if screenshot.startswith("data:image"):
                base64_image = screenshot
            elif (("/" in screenshot or "\\" in screenshot) and 
                  not screenshot.startswith(("iVBOR", "/9j", "UklG")) and
                  len(screenshot) < 1000):
                with open(screenshot, "rb") as f:
                    base64_data = base64.b64encode(f.read()).decode()
                base64_image = f"data:image/png;base64,{base64_data}"
            else:
                base64_image = f"data:image/png;base64,{screenshot}"
            content.append({"type": "input_image", "image_url": base64_image})

        input_data = [{"role": "user", "content": content}]

        def _make_request():
            model_param = model_config.get('deployment', model_config.get('type', model_config.get('model')))
            return client.responses.create(
                model=model_param,
                tools=[{
                    "type": "computer_use_preview",
                    "display_width": display_width,
                    "display_height": display_height,
                    "environment": environment
                }],
                input=input_data,
                reasoning={"summary": "concise"},
                truncation="auto"
            )

        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, _make_request)

    async def call_operator_next(self, *, previous_response_id: str, call_id: str, screenshot: str,
                                 display_width: int = 1280, display_height: int = 720,
                                 environment: str = 'browser'):
        """Operator follow-up call with previous_response_id + computer_call_output"""
        import asyncio

        client = self._get_client('operator')
        model_config = self.config['models']['operator']

        # Prepare screenshot as data URL
        if screenshot.startswith("data:image"):
            base64_image = screenshot
        elif (("/" in screenshot or "\\" in screenshot) and 
              not screenshot.startswith(("iVBOR", "/9j", "UklG")) and
              len(screenshot) < 1000):
            with open(screenshot, "rb") as f:
                base64_data = base64.b64encode(f.read()).decode()
            base64_image = f"data:image/png;base64,{base64_data}"
        else:
            base64_image = f"data:image/png;base64,{screenshot}"

        input_data = [{
            "call_id": call_id,
            "type": "computer_call_output",
            "output": {
                "type": "input_image",
                "image_url": base64_image
            }
        }]

        def _make_request():
            model_param = model_config.get('deployment', model_config.get('type', model_config.get('model')))
            return client.responses.create(
                model=model_param,
                previous_response_id=previous_response_id,
                tools=[{
                    "type": "computer_use_preview",
                    "display_width": display_width,
                    "display_height": display_height,
                    "environment": environment
                }],
                input=input_data,
                truncation="auto"
            )

        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, _make_request)
    
    async def call_coder(self, model_name: str, prompt: str, *, verbosity: str = None, reasoning_effort: str = None, stream_callback: Optional[Callable[[str], None]] = None) -> str:
        """è°ƒç”¨ä»£ç ç”Ÿæˆæ¨¡å‹
        - æ”¯æŒå¯é€‰çš„verbosityä¸reasoning_effortï¼ˆä»…GPT-5æœ‰æ•ˆï¼‰
        """
        if model_name == 'gpt5':
            v = verbosity if verbosity else "low"
            r = reasoning_effort if reasoning_effort else "low"
            return await self.call_model_with_gpt5_params(
                model_name, prompt, temperature=0.7, verbosity=v, reasoning_effort=r,
                stream_callback=stream_callback
            )
        else:
            return await self.call_model(model_name, prompt, temperature=0.7)
    
    async def call_judge(self, prompt: str, images: Optional[List[str]] = None) -> str:
        """è°ƒç”¨judgeæ¨¡å‹ - å§‹ç»ˆä½¿ç”¨GPT-5"""
        return await self.call_model('gpt5', prompt, images, temperature=0.3)
    
    async def call_task_generator(self, prompt: str) -> str:
        """è°ƒç”¨ä»»åŠ¡ç”Ÿæˆæ¨¡å‹"""
        return await self.call_model('gpt5', prompt, temperature=0.3)
    
    async def call_commenter(self, model_name: str, prompt: str, images: List[str]) -> str:
        """è°ƒç”¨commenteræ¨¡å‹è¿›è¡Œç‰ˆæœ¬é€‰æ‹© - é’ˆå¯¹ç®€çŸ­åˆ†æä»»åŠ¡ä¼˜åŒ–"""
        # å¯¹äºGPT-5ï¼Œä½¿ç”¨minimal reasoning effortå’Œlow verbosityæ¥åŠ é€Ÿ
        if model_name == 'gpt5':
            return await self.call_model_with_gpt5_params(model_name, prompt, images, 
                                                        temperature=0.3, verbosity="low", reasoning_effort="minimal")
        else:
            return await self.call_model(model_name, prompt, images, temperature=0.3)
    
    async def call_cua_model(self, model_name: str, prompt: str, images: Optional[List[str]] = None) -> str:
        """è°ƒç”¨CUAæ¨¡å‹ï¼ˆUI-TARSæˆ–operatorï¼‰"""
        if model_name == 'operator':
            # operatoræ¨¡å‹ä½¿ç”¨ç‰¹æ®Šçš„API
            screenshot = images[0] if images else None
            return await self.call_operator_model(prompt, screenshot)
        else:
            # UI-TARSç­‰å…¶ä»–CUAæ¨¡å‹ä½¿ç”¨å¸¸è§„API
            return await self.call_model(model_name, prompt, images, temperature=0.3)
